{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31.베스트모델-와인이진분류.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 베스트모델 와인 이진분류\n",
        "- 와인 데이터 사이킷런하고 달라. 등급으로 다중분류 가능하고, 레드앤 화이트로 이진분류 가능함"
      ],
      "metadata": {
        "id": "Ofi-2lHjdAND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 와인데이터 과적합 피하기"
      ],
      "metadata": {
        "id": "0EuYDCTicpQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 와인데이터는 red  white 분류 . 사이킷런의 와인데이터랑 달라"
      ],
      "metadata": {
        "id": "cURPJ2Z_ctSa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "wcMNyYAadGNq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "up = files.upload()\n",
        "filename = list(up.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "height": 78
        },
        "id": "4CotQxC5dIDj",
        "outputId": "b6931a7e-9a29-4ad2-8f6d-f30845c3255f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3de8befc-1006-49f0-83a0-38f14cfeb979\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3de8befc-1006-49f0-83a0-38f14cfeb979\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wine.csv to wine (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(filename, header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l4jpJ-FjdJuV",
        "outputId": "26c372a1-c56f-4d5a-d15b-68a13d085c8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f6f35d9-d944-48d5-a9dc-70a340b8dfc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f6f35d9-d944-48d5-a9dc-70a340b8dfc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f6f35d9-d944-48d5-a9dc-70a340b8dfc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f6f35d9-d944-48d5-a9dc-70a340b8dfc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
              "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
              "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
              "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
              "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
              "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(df.values[:, -1], return_counts=True)\n",
        "# 0 이 화이트  1이 레드 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXpOY4UXdvKB",
        "outputId": "4ab84696-a371-49e5-f561-6e1685b440f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([4898, 1599]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y 값은 01 이라 필요없고 \n",
        "# X값 스케일링\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaled = StandardScaler().fit_transform(df.values[:,:-1])"
      ],
      "metadata": {
        "id": "V-Df8Chedpey"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, df.values[:,-1], stratify =df.values[:,-1],  random_state=seed\n",
        ")\n",
        "X_train.shape, X_test.shape, y_train.shape,  y_test.shape\n",
        "# 12개의 엘리먼트 들어와. 와인등급으로 다중분류, 레드 화이트로 이진분류"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaQ9zwIgdX5v",
        "outputId": "c334ab2a-8f1a-4191-b36d-43525d1873d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4872, 12), (1625, 12), (4872,), (1625,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 정의 / 설정"
      ],
      "metadata": {
        "id": "BJaMgE0Mdjrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "4mSKw5z3iDoT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "        Dense(30, input_dim=12, activation='relu'),\n",
        "        Dense(12, activation='relu'),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK2Zo6ZOia3s",
        "outputId": "1594994d-8af7-4c53-dcc2-4450c44a525a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                390       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                372       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bqkRD_UKkuwz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 저장관련 설정"
      ],
      "metadata": {
        "id": "-OPD-xJgjC2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('model'):\n",
        "    os.mkdir('model')"
      ],
      "metadata": {
        "id": "JyiUs67MiyFO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = 'model/best_wine.h5'\n",
        "model_path = 'model/wine_{epoch:03d}_{val_loss:.4f}.h5'"
      ],
      "metadata": {
        "id": "uIfWrZGvjTfz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    model_path, monitor='val_loss', verbose=1, save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "wDZQzpfwjTXz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델학습및 저장"
      ],
      "metadata": {
        "id": "ZbSdbzUXkZRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, validation_split=0.2, verbose=0,\n",
        "                 epochs=200, batch_size=200, \n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9IJo7yckZLC",
        "outputId": "7d284210-09ca-44b6-b49a-53cb3c45042f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.24037, saving model to model/wine_001_0.2404.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.24037 to 0.14469, saving model to model/wine_002_0.1447.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.14469 to 0.09476, saving model to model/wine_003_0.0948.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.09476 to 0.06748, saving model to model/wine_004_0.0675.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.06748 to 0.05222, saving model to model/wine_005_0.0522.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.05222 to 0.04306, saving model to model/wine_006_0.0431.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.04306 to 0.03750, saving model to model/wine_007_0.0375.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.03750 to 0.03372, saving model to model/wine_008_0.0337.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.03372 to 0.03105, saving model to model/wine_009_0.0310.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.03105 to 0.02870, saving model to model/wine_010_0.0287.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.02870 to 0.02710, saving model to model/wine_011_0.0271.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.02710 to 0.02607, saving model to model/wine_012_0.0261.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.02607 to 0.02482, saving model to model/wine_013_0.0248.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.02482 to 0.02407, saving model to model/wine_014_0.0241.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.02407 to 0.02339, saving model to model/wine_015_0.0234.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.02339 to 0.02275, saving model to model/wine_016_0.0227.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.02275 to 0.02228, saving model to model/wine_017_0.0223.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.02228 to 0.02192, saving model to model/wine_018_0.0219.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.02192 to 0.02170, saving model to model/wine_019_0.0217.h5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.02170 to 0.02109, saving model to model/wine_020_0.0211.h5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.02109 to 0.02071, saving model to model/wine_021_0.0207.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.02071 to 0.02015, saving model to model/wine_022_0.0202.h5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.02015 to 0.01998, saving model to model/wine_023_0.0200.h5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01998 to 0.01949, saving model to model/wine_024_0.0195.h5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01949 to 0.01935, saving model to model/wine_025_0.0193.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01935 to 0.01896, saving model to model/wine_026_0.0190.h5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01896 to 0.01883, saving model to model/wine_027_0.0188.h5\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01883 to 0.01875, saving model to model/wine_028_0.0187.h5\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01875\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01875\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.01875 to 0.01865, saving model to model/wine_031_0.0186.h5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01865 to 0.01784, saving model to model/wine_032_0.0178.h5\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01784\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01784\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01784\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.01784 to 0.01759, saving model to model/wine_036_0.0176.h5\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01759\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.01759 to 0.01729, saving model to model/wine_038_0.0173.h5\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.01729 to 0.01713, saving model to model/wine_039_0.0171.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01713\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.01713 to 0.01693, saving model to model/wine_041_0.0169.h5\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.01693 to 0.01686, saving model to model/wine_042_0.0169.h5\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.01686 to 0.01664, saving model to model/wine_043_0.0166.h5\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.01664 to 0.01633, saving model to model/wine_044_0.0163.h5\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.01633 to 0.01609, saving model to model/wine_045_0.0161.h5\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01609\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.01609 to 0.01608, saving model to model/wine_047_0.0161.h5\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.01608 to 0.01576, saving model to model/wine_048_0.0158.h5\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.01576 to 0.01493, saving model to model/wine_049_0.0149.h5\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01493\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.01493 to 0.01492, saving model to model/wine_051_0.0149.h5\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.01492 to 0.01489, saving model to model/wine_052_0.0149.h5\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.01489 to 0.01484, saving model to model/wine_053_0.0148.h5\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.01484 to 0.01462, saving model to model/wine_054_0.0146.h5\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.01462 to 0.01437, saving model to model/wine_055_0.0144.h5\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.01437 to 0.01409, saving model to model/wine_056_0.0141.h5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.01409\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.01409 to 0.01396, saving model to model/wine_058_0.0140.h5\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.01396 to 0.01371, saving model to model/wine_059_0.0137.h5\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.01371 to 0.01366, saving model to model/wine_060_0.0137.h5\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.01366 to 0.01322, saving model to model/wine_061_0.0132.h5\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.01322 to 0.01321, saving model to model/wine_062_0.0132.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.01321\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.01321\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.01321 to 0.01316, saving model to model/wine_065_0.0132.h5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.01316\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.01316 to 0.01277, saving model to model/wine_067_0.0128.h5\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.01277\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.01277\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.01277 to 0.01277, saving model to model/wine_070_0.0128.h5\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.01277\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.01277\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.01277 to 0.01251, saving model to model/wine_073_0.0125.h5\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.01251\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.01251 to 0.01225, saving model to model/wine_075_0.0123.h5\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.01225\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.01225\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.01225 to 0.01202, saving model to model/wine_078_0.0120.h5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.01202\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.01202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 베스트 모델 로딩한 후 평가"
      ],
      "metadata": {
        "id": "MuwbmUVGkc5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "best_model_path = 'model/wine_078_0.0120.h5'\n",
        "best_model = load_model(best_model_path)\n",
        "best_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W4WL4Lqkcz7",
        "outputId": "8d91002b-1a5f-47b5-c3aa-eb66369385e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.008586783893406391, 0.9975384473800659]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  학습과정 시각화"
      ],
      "metadata": {
        "id": "kxnmrBLQmYqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_acc = hist.history['accuracy']\n",
        "y_vloss = hist.history['val_loss']\n",
        "xs = np.arange(1, len(y_acc)+1)"
      ],
      "metadata": {
        "id": "g_Pxd9FcZ0au"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(xs, y_acc, ms=5, label='train accuracy')\n",
        "plt.plot(xs, y_vloss, ms=5, label='validation loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "P1Haz2JtaDqt",
        "outputId": "1e8281dd-0264-43a5-e859-283691df5e19"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAHgCAYAAACvngt5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcVZ33+++vLn3vdDoJBEICiYAQciNJh0TDpfMEOAFnYFAgoIgwXEaO4Hh4xmNmHkcZPbxeqOjhQRmfiTMoOkJg4DCCBnFUWvRRMAQhBAISIJCEkHt30veuqnX+WLuqqzt9q6TT1WR93q9Xvapq1669V/1q167vXrWqypxzAgAAAEITK3YDAAAAgGIgCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIKUKNaKJ0yY4KZOnToi62ppaVFlZeWIrOtIQc0KQ70KR80KQ70KR80KQ70KR80KU8x6rV27dpdz7qje04sWhKdOnarnnntuRNbV0NCg+vr6EVnXkYKaFYZ6FY6aFYZ6FY6aFYZ6FY6aFaaY9TKzt/uaztAIAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAI0qBB2MzuNbMdZra+n9vNzO42s41mts7M5g1/MwEAAIDhNZQe4R9IWjbA7RdIOjk63Sjpu4feLAAAAODwSgw2g3PuaTObOsAsF0v6oXPOSXrGzMaa2bHOuW3D1EYAAFAEzjmlM06p6CRJlSVxmVmPeVo600pHt5tJVSUJxWLWY1ltnWl1pjMH3ZayZEylifhB378/Pr5Izkmu97Rour/cPV9WR9qprTMtJ5c3X/cyui/78/JkXCWJnn2QqXRGLZ3p3PXSRExlyZ6PM5NxaulMqSQRU0k8lqt//vOTzjilnVNJPKbShJ/HOafOdEadqYySfUzvSGUUM1MiZorH/Hn+slMZp45URs45JWIxJeI95zkSmMt/RvubyQfhnzrnZvZx208l3eGc+110/VeSvuCce66PeW+U7zXWxIkT569ateqQGj9Uzc3NqqqqGpF1HSlCrlnGOXVllNub5XZkefP03uG1tLSooqKy+/b88wOW4w6Y1uN2N7Rp2elpJ3VlnDrTUldG6kz79jtJyZhUEjPFTMo4Ke2c0i57Wcpk+m9Hb33tK/qqSb+397qho6NDJaWl/axrkLYMsM6+1jVgW/pYlpPfDnK1ykT1imaKma+pmf9YLWb5J1Nbyqmxw6mx3ak9Pfg+tr925Etn0orFCgsBA+3eC2vVIPMP5Xk4hHVLQ3yue8mk04rFD6zZUN73hrqeEavLQTz+/qSdov2Fv3dFwlSRNMWVVnsmptYup7aUctt/b8mYNLbUVF1iau7y23lnr3wbN6mm1FRTamqPXg9tqYNobC9VSb/uZNzU2uXU0uXUkc6rQ4H71mKoTkpjy2KKmbS33Wl/pzugPRUJ/zhL46amTqemDr8/kiSTFI917//7kzB/e+9Z+pueld2XpTP9z2Pyz7GZvzx0TivPL062WLJkyVrnXF3v6YP2CA8n59xKSSslqa6uztXX14/IehsaGjRS6xop+Ud5HSl/3uNyOq2Orow6onkyGZcLQs45ZZxTJuPf2F30Bp9/+2ubXtfUMcf7XoB0Jne0mTmIN5CszlRGO5s7tH1fu/a2dOnAl35xdaQyamrr0r62rj53/gMzSa2HoVVHMpPUWexGDEnMpEQ8pnjUC5J2/jWVdq7PgBYzaUJVqSaOKdO40risn7eK/jpV+pq+d+9e1dbWFrysgfTXq9PfogZaR//3KWwdA6+nsMe+a9cuHTVhQoHr0LA8X4Mtq8DJ0XqG5/mKm6k0GVdZ0vdM7mtLqamtS9t27NSMSRM1pjyp6rKEknFTPBZTMmaKRz2Bzkm7Wzq1fV+79rR0qraiREdXl+qo6lIl4n55zjntbunUjn0d2tncoarSuI6uLtNR1aUH9HQWoqUjpR3727V9X4c6UhnVlCdVU55QZUlCsu5aZx+39bjcfVuuLNGNvefLv3/uPr2KadH63nzzDZ144okDrq/7PqaWjpS272vX9n3tSmecjqkp01HVZRpTlsito70rrR37/ONs7UprfnWpJo4p1djyEnWmM2rv8j3riZj5Xtq85ydmpo68LFAS9891STymVMapvSutjlRGybipLJouKXqPz6gr7d/ruzIZJWO+B7k0GVPM7IA80JV2BR9Ubt68edTlseEIwlslTcm7PjmaFrz2rrTau9K5ja2tK6139rTqnT2t2rGvXc0dabV0pNTckVJLR0qtnWm1dqZyG3D3eToKt5ke4fawe3VDj6vxqGfxYCViMR1VXaqjq0t1wvgKxQ9lYYdBMh7T2IqkasqTqihJ9Nhh9rWTVO420xsbN+qkk07qtQMe+o6393w9bjtgp2w95ovH/A6tLBlXWSKWe4MzmTpSfqfXlfYfi8VjpmTMnyfifqfZe6efXUfuco/pPducP019zDfQsp555g/60Ic+1O+yrI879TXvwba7x8U+lpXI1ilmB3zEmy/70WQ6OrhMO6eyRCwXCoaLP6BfNKzLPNL5mh3QAYR++HrxffdCNGiz6s85sdjNeN9oaNhe7CYcYDiC8GOSbjazVZIWSmo6ksYHt3eltbWxTe9Gp62N7bnL7V3pA+Z3kprb/RHfvvbBPweKmVRZklBlaUKVpXFVlCRUmoipJBFTdVlCJQk/Jqokmpa9rTQeyx3llSb9mKH8ebPzZccTZUNP9qPb7MlMisW6p1t0/szvf69zzj4zF57iNnAYCF1D6m3Vnzmt2M14XxlXFtOxNeXFbsYhM/MHFSP68RoAYFgMuu82swck1UuaYGZbJH1ZUlKSnHP/S9JqSRdK2ij/2fC1h6uxI+Xld5v06w079NuNu/Snd/aqK28Qjpk0sbpMx44tU1Vp3+U7urpUHz5xvI4eU6byZFwdKf9RRkkiphPGV+j4cRU6psbfvzzZ80sHo0VViam6LFnsZgAAABw2Q/nViCsHud1J+sywtaiIGls7dfvPNug/1m6RJM2YNEZ/vXiaTj22WpNqyjVpbLmOqSlTcpg/8gQAAMDI49O8yE/XvavbHntZe1u7dFP9ibr+zGkaX9X3N9oBAADw/kcQlvTI2i367//xomZPrtEP/3qhTps0pthNAgAAwGEWfBBet6VRf//oS1r0gXH60XULGfYAAAAQiKBT3879HfqbH63VUVWluufj8wjBAAAAAQm2RziVzugzP35ee1s79fCnP8x4YAAAgMAE2wX60tYm/XHTHn3xI6dp5nE1xW4OAAAARliwQfidPf7vcBd9YFyRWwIAAIBiCDYIb46C8OTaiiK3BAAAAMUQbBB+Z0+rjq4uVVkyXuymAAAAoAiCDsLHj6M3GAAAIFTBBuHNe9o0hSAMAAAQrCCDcGcqo21NBGEAAICQBRmE321sU8aJoREAAAABCzIIZ386jSAMAAAQrqCD8JRx5UVuCQAAAIolyCC8eW+rSuIxTawuK3ZTAAAAUCRhBuE9rZo8rlyxmBW7KQAAACiSIIMwvyEMAACAMIPw7lZN4a+VAQAAghZcEG5q7dK+9hQ9wgAAAIELLghv3pv9xQiCMAAAQMiCC8L8dBoAAACkoIMwPcIAAAAhCy4Ib97TqtqKpMaUJYvdFAAAABRRcEGYn04DAACAFGAQ9n+mQRAGAAAIXVBBOJ1x2trYRo8wAAAAwgrC7+1rV1faEYQBAAAQVhB+Z3f0ixH8qxwAAEDwEsVuwEiaNblGD964SNMnjSl2UwAAAFBkQQXhqtKEFn5gfLGbAQAAgFEgqKERAAAAQBZBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJCGFITNbJmZvWZmG81sRR+3H29mT5nZn8xsnZldOPxNBQAAAIbPoEHYzOKS7pF0gaTTJF1pZqf1mu2Lkh5yzs2VdIWkfx7uhgIAAADDaSg9wmdI2uice9M51ylplaSLe83jJI2JLtdIenf4mggAAAAMv8QQ5jlO0ua861skLew1z22SfmFmt0iqlHTusLQOAAAAOEzMOTfwDGaXSlrmnLs+uv5JSQudczfnzXNrtKxvmtmHJP2bpJnOuUyvZd0o6UZJmjhx4vxVq1YN64PpT3Nzs6qqqkZkXUcKalYY6lU4alYY6lU4alYY6lU4alaYYtZryZIla51zdb2nD6VHeKukKXnXJ0fT8l0naZkkOef+YGZlkiZI2pE/k3NupaSVklRXV+fq6+uH2v5D0tDQoJFa15GCmhWGehWOmhWGehWOmhWGehWOmhVmNNZrKGOE10g62cymmVmJ/JfhHus1zzuSlkqSmU2XVCZp53A2FAAAABhOgwZh51xK0s2SnpS0Qf7XIV42s6+Y2UXRbP9d0g1m9qKkByRd4wYbcwEAAAAU0VCGRsg5t1rS6l7TvpR3+RVJi4e3aQAAAMDhwz/LAQAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAI0pCCsJktM7PXzGyjma3oZ57LzewVM3vZzO4f3mYCAAAAwysx2AxmFpd0j6TzJG2RtMbMHnPOvZI3z8mS/l7SYufcXjM7+nA1GAAAABgOQ+kRPkPSRufcm865TkmrJF3ca54bJN3jnNsrSc65HcPbTAAAAGB4DSUIHydpc971LdG0fB+U9EEz+99m9oyZLRuuBgIAAACHgznnBp7B7FJJy5xz10fXPylpoXPu5rx5fiqpS9LlkiZLelrSLOdcY69l3SjpRkmaOHHi/FWrVg3jQ+lfc3OzqqqqRmRdRwpqVhjqVThqVhjqVThqVhjqVThqVphi1mvJkiVrnXN1vacPOkZY0lZJU/KuT46m5dsi6VnnXJekt8zsz5JOlrQmfybn3EpJKyWprq7O1dfXD/kBHIqGhgaN1LqOFNSsMNSrcNSsMNSrcNSsMNSrcNSsMKOxXkMZGrFG0slmNs3MSiRdIemxXvP8p6R6STKzCfJDJd4cxnYCAAAAw2rQIOycS0m6WdKTkjZIesg597KZfcXMLopme1LSbjN7RdJTkj7vnNt9uBoNAAAAHKqhDI2Qc261pNW9pn0p77KTdGt0AgAAAEY9/lkOAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACFKi2A0AAAAYzbq6urRlyxa1t7f3mF5TU6MNGzYUqVXvPyNRr7KyMk2ePFnJZHJI8xOEAQAABrBlyxZVV1dr6tSpMrPc9P3796u6urqILXt/Odz1cs5p9+7d2rJli6ZNmzak+zA0AgAAYADt7e0aP358jxCM0cfMNH78+AN67gdCEAYAABgEIfj9odDniSAMAAAwijU2Nuqf//mfD+q+F154oRobG4e5RUcOgjAAAMAoNlAQTqVSA9539erVGjt27OFo1iFxzimTyRS7GQRhAACA0WzFihV64403dPrpp+vzn/+8GhoadNZZZ+miiy7SaaedJkn6q7/6K82fP18zZszQypUrc/edOnWqdu3apU2bNmn69Om64YYbNGPGDJ1//vlqa2s7YF2PP/64Fi5cqLlz5+rcc8/V9u3bJUnNzc269tprNWvWLM2ePVuPPPKIJOnnP/+55s2bpzlz5mjp0qWSpNtuu0133nlnbpkzZ87Upk2b9Pbbb+uUU07R1VdfrZkzZ2rz5s266aabVFdXpxkzZujLX/5y7j5r1qzRhz/8Yc2ZM0dnnHGG9u/fr7PPPlsvvPBCbp4zzzxTL7744iHVll+NAAAAGKJ/evxlvfLuPklSOp1WPB4/5GWeNmmMvvyXM/q9/Y477tD69etzIbChoUHPP/+81q9fn/t1hHvvvVfjxo1TW1ubFixYoI997GMaP358j+W8/vrreuCBB/S9731Pl19+uR555BFdddVVPeY588wz9cwzz8jM9K//+q/6+te/rm9+85v66le/qpqaGr300kuSpL1792rnzp264YYb9PTTT2vatGnas2fPoI/19ddf13333adFixZJkm6//XaNGzdO6XRaS5cu1bp163Tqqadq+fLlevDBB7VgwQLt27dP5eXluu666/SDH/xAd911l/785z+rvb1dc+bMGXqh+0AQBgAAeJ8544wzevxE2N13361HH31UkrR582a9/vrrBwThadOm6fTTT5ckzZ8/X5s2bTpguVu2bNHy5cu1bds2dXZ25tbxy1/+UqtWrcrNV1tbq8cff1xnn312bp5x48YN2u4TTjghF4Il6aGHHtLKlSuVSqW0bds2vfLKKzIzHXvssVqwYIEkacyYMZKkyy67TF/96lf1jW98Q/fee6+uueaaQdc3GIIwAADAEOX33Bbzd4QrKytzlxsaGvTLX/5Sf/jDH1RRUaH6+vo+f0KstLQ0dzkej/c5NOKWW27RrbfeqosuukgNDQ267bbbCm5bIpHoMf43vy357X7rrbd05513as2aNaqtrdU111wz4E+fVVRU6LzzztNPfvITPfTQQ1q7dm3BbeuNMcIAAACjWHV1tfbv39/v7U1NTaqtrVVFRYVeffVVPfPMMwe9rqamJh133HGSpPvuuy83/bzzztM999yTu753714tWrRITz/9tN566y1Jyg2NmDp1qp5//nlJ0vPPP5+7vbd9+/apsrJSNTU12r59u5544glJ0imnnKJt27ZpzZo1kvwBR/ZLgddff70++9nPasGCBaqtrT3ox5lFEAYAABjFxo8fr8WLF2vmzJn6/Oc/f8Dty5YtUyqV0vTp07VixYoeQw8Kddttt+myyy7T/PnzNWHChNz0L37xi9q7d69mzpypOXPm6KmnntJRRx2llStX6qMf/ajmzJmj5cuXS5I+9rGPac+ePZoxY4a+853v6IMf/GCf65ozZ47mzp2rU089VR//+Me1ePFiSVJJSYkefPBB3XLLLZozZ47OO++8XE/x/PnzNWbMGF177bUH/RjzMTQCAABglLv//vt7XK+vr89dLi0tzfWm9pYdBzxhwgStX78+N/3v/u7v+pz/4osv1sUXX3zA9Kqqqh49xFkXXHCBLrjggh7TysvL9Ytf/OKAeffv39+jDZL0gx/8oM92LFiwoM+e7XfffVeZTEbnn39+n/crFD3CAAAAGPV++MMfauHChbr99tsViw1PhKVHGAAAAKPe1VdfrauvvnpYl0mPMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAHGGqqqok+Z8bu/TSS/ucp76+Xs8999yAy7nrrrvU2tqau37hhReqsbHxkNt322236c477zzk5RwqgjAAAMARatKkSXr44YcP+v69g/Dq1as1duzY4WjaqEAQBgAAGMVWrFjR4++Ns72pzc3NWrp0qebNm6dZs2bpJz/5yQH33bRpk2bOnClJamtr0xVXXKHp06frkksuUVtbW26+m266SXV1dZoxY4a+/OUvS5Luvvtuvfvuu1qyZImWLFkiyf998q5duyRJ3/rWtzRz5kzNnDlTd911V25906dP1w033KAZM2bo/PPP77GevrzwwgtatGiRZs+erUsuuUR79+7Nrf+0007T7NmzdcUVV0iSfvOb3+j000/X6aefrrlz5w7419NDwe8IAwAADNUTK6T3XpIkladTUnwYotQxs6QL7uj35uXLl+tzn/ucPvOZz0iSHnroIT355JMqKyvTo48+qjFjxmjXrl1atGiRLrroIplZn8v57ne/q4qKCm3YsEHr1q3TvHnzcrfdfvvtGjdunNLptJYuXap169bps5/9rL71rW/pqaee6vF3y5K0du1aff/739ezzz4r55wWLlyoc845R7W1tXr99df1wAMP6Hvf+54uv/xyPfLII7rqqqv6fXxXX321vv3tb+ucc87Rl770Jf3TP/2T7rrrLt1xxx166623VFpamhuOceedd+qee+7R4sWL1dzcrLKysiGXuS/0CAMAAIxic+fO1Y4dO/Tuu+/qxRdfVG1traZMmSLnnP7hH/5Bs2fP1rnnnqutW7dq+/bt/S7n6aefzgXS2bNna/bs2bnbHnroIc2bN09z587Vyy+/rFdeeWXANv3ud7/TJZdcosrKSlVVVemjH/2ofvvb30qSpk2bptNPP12SNH/+/NzfPPelqalJjY2NOueccyRJn/rUp/T000/n2viJT3xC//7v/65Ewh9wLF68WLfeeqvuvvtuNTY25qYfLHqEAQAAhiqv57Zt/35VV1ePyGovu+wyPfzww3rvvfe0fPlySdKPf/xj7dy5U2vXrlUymdTUqVPV3t5e8LLfeust3XnnnVqzZo1qa2t1zTXXHNRyskpLS3OX4/H4oEMj+vOzn/1MTz/9tB5//HHdfvvteumll7RixQp95CMf0erVq7V48WI9+eSTOvXUUw+6rfQIAwAAjHLLly/XqlWr9PDDD+uyyy6T5HtTjz76aCWTST311FN6++23B1zG2Wefrfvvv1+StH79eq1bt06StG/fPlVWVqqmpkbbt2/XE088kbtPdXV1n+NwzzrrLP3nf/6nWltb1dLSokcffVRnnXVWwY+rpqZGtbW1ud7kH/3oRzrnnHOUyWS0efNmLVmyRF/72tfU1NSk5uZmvfHGG5o1a5a+8IUvaMGCBXr11VcLXmc+eoQBAABGuRkzZmj//v067rjjdOyxx0qSPvGJT+gv//IvNWvWLNXV1Q3aM3rTTTfp2muv1fTp0zV9+nTNnz9fkjRnzhzNnTtXp556qqZMmaLFixfn7nPjjTdq2bJlmjRpkp566qnc9Hnz5umaa67RGWecIUm6/vrrNXfu3AGHQfTnvvvu06c//Wm1trbqAx/4gL7//e8rnU7rqquuUlNTk5xz+uxnP6uxY8fqH//xH/XUU08pFotpxowZuuCCCwpeXz5zzh3SAg5WXV2dG+y364ZLQ0OD6uvrR2RdRwpqVhjqVThqVhjqVThqVhjq1b8NGzZo+vTpB0zfP4JDI44EI1Wvvp4vM1vrnKvrPS9DIwAAABAkgjAAAACCRBAGAABAkAjCAAAAgyjWd6pQmEKfJ4IwAADAAMrKyrR7927C8CjnnNPu3bsL+rc5fj4NAABgAJMnT9aWLVu0c+fOHtPb29sP+S9+QzIS9SorK9PkyZOHPD9BGAAAYADJZFLTpk07YHpDQ4Pmzp1bhBa9P43GejE0AgAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCANKQib2TIze83MNprZigHm+5iZOTOrG74mAgAAAMNv0CBsZnFJ90i6QNJpkq40s9P6mK9a0t9Kena4GwkAAAAMt6H0CJ8haaNz7k3nXKekVZIu7mO+r0r6mqT2YWwfAAAAcFgMJQgfJ2lz3vUt0bQcM5snaYpz7mfD2DYAAADgsDHn3MAzmF0qaZlz7vro+iclLXTO3Rxdj0n6taRrnHObzKxB0t85557rY1k3SrpRkiZOnDh/1apVw/lY+tXc3KyqqqoRWdeRgpoVhnoVjpoVhnoVjpoVhnoVjpoVppj1WrJkyVrn3AHfYUsM4b5bJU3Juz45mpZVLWmmpAYzk6RjJD1mZhf1DsPOuZWSVkpSXV2dq6+vL+QxHLSGhgaN1LqOFNSsMNSrcNSsMNSrcNSsMNSrcNSsMKOxXkMZGrFG0slmNs3MSiRdIemx7I3OuSbn3ATn3FTn3FRJz0g6IAQDAAAAo8mgQdg5l5J0s6QnJW2Q9JBz7mUz+4qZXXS4GwgAAAAcDkMZGiHn3GpJq3tN+1I/89YferMAAACAw4t/lgMAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACvkwXsAABt9SURBVCBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJAIwgAAAAgSQRgAAABBIggDAAAgSARhAAAABIkgDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEEiCAMAACBIBGEAAAAEiSAMAACAIBGEAQAAECSCMAAAAIJEEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJDCCsKpDmn3G1JnS7FbAgAAgCILKwhvflb69jxp69pitwQAAABFFlYQrpjgz1t3F7cdAAAAKLrAgvB4f96yq7jtAAAAQNEFFoTH+fPWPcVtBwAAAIourCAcT0plNVIrPcIAAAChCysIS354BGOEAQAAghdgEJ7AGGEAAACEGITHM0YYAAAAAQbhyvGMEQYAAECAQTg7Rti5YrcEAAAARRRgEJ4gpTulzuZitwQAAABFFGAQ5k81AAAAEHIQ5gtzAAAAQRtSEDazZWb2mpltNLMVfdx+q5m9YmbrzOxXZnbC8Dd1mFRO8Od8YQ4AACBogwZhM4tLukfSBZJOk3SlmZ3Wa7Y/Sapzzs2W9LCkrw93Q4dN7m+W+VMNAACAkA2lR/gMSRudc2865zolrZJ0cf4MzrmnnHOt0dVnJE0e3mYOo4qoR5gxwgAAAEEbShA+TtLmvOtbomn9uU7SE4fSqMOqtFqKJekRBgAACJy5QX5P18wulbTMOXd9dP2TkhY6527uY96rJN0s6RznXEcft98o6UZJmjhx4vxVq1Yd+iMYgubmZlVVVeWuf+j312rPuHl67dRbRmT970e9a4aBUa/CUbPCUK/CUbPCUK/CUbPCFLNeS5YsWeucq+s9PTGE+26VNCXv+uRoWg9mdq6k/6F+QrAkOedWSlopSXV1da6+vn4Iqz90DQ0N6rGuDZN0bE2Jjh2h9b8fHVAzDIh6FY6aFYZ6FY6aFYZ6FY6aFWY01msoQyPWSDrZzKaZWYmkKyQ9lj+Dmc2V9C+SLnLO7Rj+Zg6zivGMEQYAAAjcoEHYOZeSH+7wpKQNkh5yzr1sZl8xs4ui2b4hqUrSf5jZC2b2WD+LGx2yf7MMAACAYA1laIScc6slre417Ut5l88d5nYdXgRhAACA4IX3z3KS/1ON9kYp3VXslgAAAKBIwgzC2b9Zbttb3HYAAACgaMIOwnxhDgAAIFhhB2HGCQMAAAQrzCBcGf3Ncis9wgAAAKEKMwjTIwwAABC8sINwC0EYAAAgVGEG4XhSKq2hRxgAACBgYQZhSaoYRxAGAAAIWLhBuHICX5YDAAAIWLhBmL9ZBgAACFrAQXgCX5YDAAAIWMBBOBoj7FyxWwIAAIAiCDcIV06Q0h1SZ3OxWwIAAIAiCDcI86caAAAAQQs4CEd/s8w4YQAAgCAFHISzPcL8hBoAAECIwg3CNZP9eeM7xW0HAAAAiiLcIFx9jFRSJe16vdgtAQAAQBGEG4TNpPEnSbv+XOyWAAAAoAjCDcKSNOFkaffGYrcCAAAARRB2EB5/stS0WepsLXZLAAAAMMLCDsITTvLne94objsAAAAw4gIPwh/053xhDgAAIDhhB+FxJ/pzxgkDAAAEJ+wgXFIh1UyhRxgAACBAYQdhiZ9QAwAACBRBOPsTas4VuyUAAAAYQQTh8SdLnc3S/veK3RIAAACMIILwhJP9+W7GCQMAAISEIJwNwnxhDgAAICgE4epJUrKCn1ADAAAIDEE4FpPGn8gvRwAAAASGICz5L8wxNAIAACAoBGHJjxNufEfqai92SwAAADBCCMKSNOGDkpy0581itwQAAAAjhCAs+X+XkxgnDAAAEBCCsCQdPV1KlEtv/77YLQEAAMAIIQhLUqJUmnaWtPGXxW4JAAAARghBOOukc6U9bzBOGAAAIBAE4awTl/rzjb8qbjsAAAAwIgjCWeNPlMaeIL3x62K3BAAAACOAIJxl5odHvPkbKdVZ7NYAAADgMCMI5ztpqdTVIm1+ptgtAQAAwGFGEM437WwplmCcMAAAQAAIwvlKq6XjP0QQBgAACABBuLeTlkrbX5L2v1fslgAAAOAwIgj3lv0ZtT//vLjtAAAAwGFFEO7tmFnSxJnS778tpVPFbg0AAAAOE4Jwb2bSOV+Qdm+U1j9S7NYAAADgMCEI9+XUv5AmzpJ+8zV6hQEAAI5QBOG+xGJS/RekPW9I6x8udmsAAABwGBCE+3PKR6Je4a/TKwwAAHAEIgj3JxaT6lf4XuE//bDYrQEAAMAwIwgP5NSP+H+be+IL0uY/Frs1AAAAGEYE4YGYSZfdJ405Tlr1canxnWK3CAAAAMOEIDyYinHSxx+UUh3SA1dKHc3FbhEAAACGAUF4KI46Rbrs+9KOV6QffETa/UaxWwQAAIBDRBAeqpPOlZb/WNq7SfqXs6UXVxW7RQAAADgEBOFCnHqhdNP/lo6ZLT36N9KPL5fe/VOxWwUAAICDQBAuVM1k6ZqfSufeJm1+VlpZ7wPxW7+VMpkiNw4AAABDlSh2A96XYnHpzP9LqrtO+uO/SH+4R7rvL6TqSdLMj0ozLpEmzfO/RQwAAIBRiSB8KMrGSGd/Xlr0f0qvPSGtf0R69l+kP3xHqjpGOmWZdOJS6bj50phJ/ufYAAAAMCoQhIdDSaU061J/atsr/fkX0ms/k156WFr7Az9P1UTpmFlS7TSpdmre6QSptLp4bQcAAAgUQXi4lddKc5b7U6pD2rZOevd5aetaaeer0uY1UkdTz/tUTOgOxTVTpMoJUsX4vNM4f146hl5lAACAYUIQPpwSpdKUBf6Ur22v/xm23qeta6VXfiJlUn0vL5aQysf5YFxaLZVU+fPc5aruabnbqqSSaql8bHS/GsYuAwAAiCBcHOW1/jRp7oG3OSd17Jdad0ute6LzXqe2Pf4f7jr2S/u3+cud+/11N8gvV1hMSpRJ8aQUL/HDOspqpLKxUrLch+1YXNN37ZH23J+77s8TQ7yeNy1RLlUf48dIl9dK7U2+/Z0tPqyX1fjAbjFJ5nu8k+W+jdneb+f844rFh/2pAAAA4SIIjzZm/kt4ZWOkcdMKu69zUleb1BmF5I793ZfbGn1PdNseKdUupbukdKcP0e2N/vb2RimTljIpVTfvk7o25653n3pdHyx4H7QoEGfSvp1yUrzU92yXjonCfEKKJX2ojyV8sM9dTka35c8TXY+X9HFb/n0GWF6y3If6igndPevOyTJdvv4MXQHwfpfqkPa/538ulA4IHOEIwkcSM6mkwp+qjj6kRf2xoUH19fWDz5jJSC4vHKe7eoblrlbfa71vmw/i5WN9z3BJpe8Vbt8ndezzIVJRz29Xm79fV1t3II0lpK6WKLA3+XCc7pIyXf68q80vJ53qnpbp6nk9f365Q6qPYkk/1CQ68DjHZaTfJXwvd0lVXi95XLLs5Vh0OdtbXup7zJNlPc9dFP7TnX6+ZIUP/skKP0+y3K/fYv45T5T5g4OyMX6ZisJ4JtV9MJTu9AcSiegUL5USUV1Tnf7gyKX90JvKCb6nvqvNP0ep9p4HBtlPE2KJ6Dls8uvIfsJQUulrEE921yvV4edLVvjhOoVwzm87XW1S9bE9h/Y45x9n/rok/7x37o+2K/mal1T3vG+6y29/pdW+Fr1lMlKqzbc9+zzEE36Z6S5fl2w9s7rapJZdfjuLl/rnJlHiL8eTUcB4178eUu3d3wNIlPntt2O/X3ay3L+OE+W5g6uytvekNxukPW9JrbukmuOl8Sf5sNLZ7D9Bam/y20h2eFQm5deZ7vJ1Lx/nX38u0/0aS7VFr7m2nge2bY1S83s+EJVUSkefJk2c6beztkZ/UN22t/uUapeSlb7t8ZKeB8/ZfYQUbas1vn0WfQqUTkktO/y62vb4x11a7Wve1err0tXq92tjj5fGTPb7g+advhay6PVTJjXvkBrflhrf0fTt26X9j/YaMlblXz8uE53S0bnrnpZJ592enSe6PV7i2zD2BP9Yt6/33wVpesc/l1XH+Bp3Rp0MnS3+cZTV+PPsc5Jq96/LVHt06oieq04/b9VEf5L8sjqbfbv6en2kO319Olv8fqGsJtoflCu3r8vuYyW/H8q+VuMl0brbdOLGtdLG26VtL0rpDn//o6f7U3mtf+6SZX47a93jt9lEWfdzldveOv1yk+X+1NYoNW/3z02mq3s/WDnBfy9m7PEHfmnc9bGPzqS6a2XWvd+LJXyb2pv8dpyM3geT2VO5r8v+96R9W/z2Wnm079SoPsbfP/uJpC9Q9HpujWrfEu1LW/y0RKn/FLVsjI7e/pK05o3oeS73dSob69vaHnVAZdLRviLaRrOXY7FoH5buuS1K3ftbi/l9dDp6HVus5yl7oJJ9f8tkut8neryfpKKOoFK/7Oz22d7k15ldXrKye/vJ7ld7PBXR9tbZ4pdh8e7vMSVKu7ft7Pac6vDLrT7G77/7el6LjCCMQxOLSYodGETyHXXKiDVnyDLpnsE4F+J7h+ZewbqzxYeYfVv9G3bSv5m8tXmbpk2e2P2GfUAIyEQ96OnuA4XOVj/UpSt6I+xq8+cWj0Jq0s+fPTDob+z4aBUv8W9C2Tf6rJIqqWqiFrR3SS/GDwwF8VKp6ij/RpXpkva86XfW2WWOPd6/Abbs9G+u6U7/plJW4+/b3ujfoHuzmA+CpVXdn4Dktyn75pUNhunOA5cRS3SHo/zHWVLlH0dXywAFMR3KAdgiSXr2oO8eFotLNcepuqNLenWD/+Qr1Xb41pcol8ZOiYaz7eo5vaTCv9Z7rz+W6A5FuYPUaNja9leibbsjb1llflvrSzwZ7Ysq/P6lY59/zaTadUDAM+t3X3KcJaXJ86WFN0rjPiDtel167yXpjV/7g8bs9m2xKPDV+O2+o9nfFktGB34lUQdFq38dlVRL1RP9azpRFh1spPwBxKs/6/u1djjFS3vW9hCcJkkbhmVRQTjbktLZ2wbODCOMIIwwxaIeCZUNy+LebmjQtKH0oB+KbM93V5sPiM75oJzqjHoT9/k3pVwvaKL7C5TxEr/jz/YspNr95Uyq+81Y8uG+dXd3721JpX8zz6T8m1XuQCHqkS+p8j0HJVXdvQT5vSidLd0htazGX2/eLu1/T63bt6ny2Ml5ASDqpU51+J6jlh1SrEqadZk07kQ/X+Pb/oulHfv9AVbV0f5NNvfG3xF96jAub+y5fPuzQ4M69vvQm+357miOejcbfY9Jrge+vLsHJ5PqPiCJxbvDS7qzu9c9XipVjvfDZnL1zvbyRefxUmnMsb5nJFne/T2AVIevY2m1v29X6wHh6dXX39Spi873P8FYMV5q2izt3ig1bfX3zf6yTKq9u/cq29ZYsrvXuG2vn57trct/vNneJSdfm+pjfK9ke5O042Vp+8u+XRXR9xyyPcwV46J2t3WHn1iy13cG4j4Adez3y+toVo8eysoJfn0V47sfQ7Z3r7Q66u3d7reBpq1+26482q9b6j6gqhjne4zjiZ6fbKVTPXtWe/eq5a5bdB7ve56uVqnxHX/q2C9NnCGNP9lvO9nXaXtT1Oa8TwvS0YF0PBn1yg3y9uucX47F/OtwOIcoZD/t6GzpPpBMlOnp3z+r+iVL+79fOjpQTFYO/UvXmfTAbc9k/Gu9q7WPG3sNNYvFu/dXLtP9iWIm1f1dl0SZ3w6y+6Lsa8ml/etuzCRfz/Z9vkOjeXvU0+6izdF170OT5d1fOC+p9JeTlb4GUQ/0s889r4Vn/jd/EJLq7P6EJJbo/gQ0lnfAn3+eSUW947Ge25yU1wGT7vmpUv4nF/mfVmSH78Xi3e8TqfxPVeN+WdlOh+x3dMpqug/wM+mo93tf91DJvp6LRHTwn/0UIPu+kerM6/nOO0935T5demfDnzR1FIVgaYhB2MyWSfqfkuKS/tU5d0ev20sl/VDSfEm7JS13zm0a3qYCgcsOSygbU+yWDIuXhzr8BpKk95obdOq0s7snHHXKyH3aUnWUVFUvfaB+ZNaXKPVv0L2NneJPByOeDSZjD61tJZXdwwX6XE/Sh/q+pheybrNDb2t/YrHuoRE91jlI2I4npHiBv3s/WICPRR+bH4zy2r6nl1R0HyD1J/tdnP6ex4FkazdmktoqtvuD26yqowpfXkA2tTdoarEb0cugh3RmFpd0j6QL5D8FuNLMTus123WS9jrnTpL0/0r62nA3FAAAABhOQ/ls4wxJG51zbzrnOiWtknRxr3kulnRfdPlhSUvN+Po8AAAARq+hBOHjJG3Ou74lmtbnPM65lKQmSeOHo4EAAADA4WBukJ+yMLNLJS1zzl0fXf+kpIXOuZvz5lkfzbMluv5GNM+uXsu6UdKNkjRx4sT5q1atGs7H0q/m5mZVVRX4k02Bo2aFoV6Fo2aFoV6Fo2aFoV6Fo2aFKWa9lixZstY5V9d7+lC+LLdVUv63EyZH0/qaZ4uZJSTVyH9prgfn3EpJKyWprq7OjdQXZRr4Uk7BqFlhqFfhqFlhqFfhqFlhqFfhqFlhRmO9hjI0Yo2kk81smpmVSLpC0mO95nlM0qeiy5dK+rUbrKsZAAAAKKJBe4Sdcykzu1nSk/I/n3avc+5lM/uKpOecc49J+jdJPzKzjZL2yIdlAAAAYNQa0u8IO+dWS1rda9qX8i63S7pseJsGAAAAHD5D/GsYAAAA4MhCEAYAAECQCMIAAAAIEkEYAAAAQSIIAwAAIEgEYQAAAASJIAwAAIAgEYQBAAAQJIIwAAAAgkQQBgAAQJDMOVecFZvtlPT2CK1ugqRdI7SuIwU1Kwz1Khw1Kwz1Khw1Kwz1Khw1K0wx63WCc+6o3hOLFoRHkpk955yrK3Y73k+oWWGoV+GoWWGoV+GoWWGoV+GoWWFGY70YGgEAAIAgEYQBAAAQpFCC8MpiN+B9iJoVhnoVjpoVhnoVjpoVhnoVjpoVZtTVK4gxwgAAAEBvofQIAwAAAD0c8UHYzJaZ2WtmttHMVhS7PaONmU0xs6fM7BUze9nM/jaafpuZbTWzF6LThcVu62hiZpvM7KWoNs9F08aZ2X+Z2evReW2x2zkamNkpedvRC2a2z8w+xzbWk5nda2Y7zGx93rQ+tynz7o72a+vMbF7xWl4c/dTrG2b2alSTR81sbDR9qpm15W1r/6t4LS+efmrW7+vQzP4+2sZeM7P/ozitLp5+6vVgXq02mdkL0XS2MQ2YKUbtvuyIHhphZnFJf5Z0nqQtktZIutI590pRGzaKmNmxko51zj1vZtWS1kr6K0mXS2p2zt1Z1AaOUma2SVKdc25X3rSvS9rjnLsjOuiqdc59oVhtHI2i1+RWSQslXSu2sRwzO1tSs6QfOudmRtP63KaisHKLpAvla/k/nXMLi9X2YuinXudL+rVzLmVmX5OkqF5TJf00O1+o+qnZberjdWhmp0l6QNIZkiZJ+qWkDzrn0iPa6CLqq169bv+mpCbn3FfYxrwBMsU1GqX7siO9R/gMSRudc2865zolrZJ0cZHbNKo457Y5556PLu+XtEHSccVt1fvWxZLuiy7fJ//iR09LJb3hnBupP9N533DOPS1pT6/J/W1TF8u/OTvn3DOSxkZvQMHoq17OuV8451LR1WckTR7xho1i/Wxj/blY0irnXIdz7i1JG+XfU4MxUL3MzOQ7jB4Y0UaNcgNkilG7LzvSg/BxkjbnXd8iQl6/oiPauZKejSbdHH1UcS8f8x/ASfqFma01sxujaROdc9uiy+9Jmlicpo1qV6jnGwfb2MD626bYtw3uryU9kXd9mpn9ycx+Y2ZnFatRo1Rfr0O2sYGdJWm7c+71vGlsY3l6ZYpRuy870oMwhsjMqiQ9Iulzzrl9kr4r6URJp0vaJumbRWzeaHSmc26epAskfSb6CC3H+TFHR+64o4NgZiWSLpL0H9EktrECsE0NnZn9D0kpST+OJm2TdLxzbq6kWyXdb2ZjitW+UYbX4cG5Uj0P6tnG8vSRKXJG277sSA/CWyVNybs+OZqGPGaWlN9gf+yc+/8kyTm33TmXds5lJH1PgX0kNhjn3NbofIekR+Xrsz37kU50vqN4LRyVLpD0vHNuu8Q2NkT9bVPs2/phZtdI+gtJn4jecBV9vL87urxW0huSPli0Ro4iA7wO2cb6YWYJSR+V9GB2GttYt74yhUbxvuxID8JrJJ1sZtOi3qgrJD1W5DaNKtE4p3+TtME596286fljdC6RtL73fUNlZpXRlwBkZpWSzpevz2OSPhXN9ilJPylOC0etHj0obGND0t829Zikq6NvXC+S/8LOtr4WEBIzWybp/5Z0kXOuNW/6UdEXNWVmH5B0sqQ3i9PK0WWA1+Fjkq4ws1IzmyZfsz+OdPtGqXMlveqc25KdwDbm9ZcpNIr3ZYmRXNlIi745fLOkJyXFJd3rnHu5yM0abRZL+qSkl7I/AyPpHyRdaWany398sUnS3xSneaPSREmP+te7EpLud8793MzWSHrIzK6T9Lb8Fymg3AHDeeq5HX2dbaybmT0gqV7SBDPbIunLku5Q39vUavlvWW+U1Cr/CxxB6adefy+pVNJ/Ra/PZ5xzn5Z0tqSvmFmXpIykTzvnhvqlsSNGPzWr7+t16Jx72cwekvSK/DCTz4T0ixFS3/Vyzv2bDvyug8Q2ltVfphi1+7Ij+ufTAAAAgP4c6UMjAAAAgD4RhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGACKwMzSZvZC3mnFMC57qpnxu8wAMIgj+neEAWAUa3POnV7sRgBAyOgRBoBRxMw2mdnXzewlM/ujmZ0UTZ9qZr82s3Vm9iszOz6aPtHMHjWzF6PTh6NFxc3se2b2spn9wszKi/agAGCUIggDQHGU9xoasTzvtibn3CxJ35F0VzTt25Luc87NlvRjSXdH0++W9Bvn3BxJ8yRl/z3zZEn3OOdmSGqU9LHD/HgA4H2Hf5YDgCIws2bnXFUf0zdJ+m/OuTfNLCnpPefceDPbJelY51xXNH2bc26Cme2UNNk515G3jKmS/ss5d3J0/QuSks65/+fwPzIAeP+gRxgARh/Xz+VCdORdTovvhADAAQjCADD6LM87/0N0+feSroguf0LSb6PLv5J0kySZWdzMakaqkQDwfkcPAQAUR7mZvZB3/efOuexPqNWa2Tr5Xt0ro2m3SPq+mX1e0k5J10bT/1bSSjO7Tr7n9yZJ2w576wHgCMAYYQAYRaIxwnXOuV3FbgsAHOkYGgEAAIAg0SMMAACAINEjDAAAgCARhAEAABAkgjAAAACCRBAGAABAkAjCAAAACBJBGAAAAEH6/wHDYURAot8yTwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1-MyTj9cpL5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}